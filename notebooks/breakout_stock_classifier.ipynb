{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0b1067",
   "metadata": {},
   "source": [
    "# Breakout Stock Classifier: Scaffolding and Expansion\n",
    "\n",
    "This notebook scaffolds a modular backend for a breakout stock classifier, breaks out model components, adds data point functionality, displays and edits the training cell, and updates the workflow to handle more stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27461137",
   "metadata": {},
   "source": [
    "## Google Colab: Uploading Your CSV\n",
    "\n",
    "If you are using Google Colab, you can upload your `stocks-list.csv` file directly to the Colab runtime with the following code cell:\n",
    "\n",
    "```python\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # This will prompt you to select and upload your CSV file\n",
    "```\n",
    "\n",
    "- After uploading, the file will be in the current working directory.\n",
    "- If your code expects the file in a `data/` folder, move it with:\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.replace('stocks-list.csv', 'data/stocks-list.csv')\n",
    "```\n",
    "\n",
    "Alternatively, you can mount your Google Drive and access files from there:\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# Then use the path: '/content/drive/My Drive/path/to/stocks-list.csv'\n",
    "```\n",
    "\n",
    "Adjust your code to use the correct path depending on your upload method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca445b9",
   "metadata": {},
   "source": [
    "## 1. Scaffold Model Backend\n",
    "Set up the basic backend structure for the breakout classifier, including imports and class/function definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and backend scaffolding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# Placeholder for backend class\n",
    "class BreakoutStockClassifier:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.features = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model = XGBClassifier(n_estimators=200, max_depth=5, random_state=42)\n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1] if self.model else None\n",
    "    \n",
    "    def save(self, path):\n",
    "        joblib.dump(self.model, path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.model = joblib.load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c6826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EOD Historical Data: Download US stock price data (replace Alpha Vantage) ---\n",
    "\n",
    "from eodhd import APIClient\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Use your actual EODHD API token here\n",
    "EODHD_API_KEY = \"68ebce6775f004.44089353\"\n",
    "\n",
    "def download_eodhd_bulk(tickers, api_key=EODHD_API_KEY, start_date=\"2015-01-01\", end_date=None, batch_size=5, delay=2):\n",
    "    \"\"\"\n",
    "    Download daily historical data for a list of tickers from EODHD.\n",
    "    Returns a DataFrame with all data concatenated.\n",
    "    Ensures 'close' column exists for all tickers.\n",
    "    \"\"\"\n",
    "    client = APIClient(api_key)\n",
    "    all_data = []\n",
    "    total = len(tickers)\n",
    "    for i in range(0, total, batch_size):\n",
    "        batch = tickers[i:i+batch_size]\n",
    "        print(f\"Downloading batch {i//batch_size+1} ({i+1}-{min(i+batch_size, total)}) of {total}...\")\n",
    "        for ticker in batch:\n",
    "            try:\n",
    "                df = client.get_historical_data(\n",
    "                    symbol=ticker,\n",
    "                    interval=\"d\",\n",
    "                    iso8601_start=start_date,\n",
    "                    iso8601_end=end_date if end_date else \"\"\n",
    "                )\n",
    "                if not df.empty:\n",
    "                    if 'close' not in df.columns:\n",
    "                        print(f\"Ticker {ticker} missing 'close' column, adding as NaN.\")\n",
    "                        df['close'] = np.nan\n",
    "                    df['symbol'] = ticker\n",
    "                    all_data.append(df)\n",
    "                else:\n",
    "                    print(f\"No data for {ticker}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {ticker}: {e}\")\n",
    "        if i + batch_size < total:\n",
    "            print(f\"Sleeping for {delay} seconds to avoid API rate limits...\")\n",
    "            time.sleep(delay)\n",
    "    if all_data:\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No valid data downloaded.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage:\n",
    "# us_tickers = [\"AAPL\", \"MSFT\", \"GOOG\"]\n",
    "# df = download_eodhd_bulk(us_tickers)\n",
    "# print(df.head())\n",
    "\n",
    "# Remove Alpha Vantage import and function\n",
    "def download_alpha_vantage_bulk(*args, **kwargs):\n",
    "    raise NotImplementedError(\"Alpha Vantage integration has been replaced by EODHD.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download and use a comprehensive ticker list from an external CSV ---\n",
    "import os\n",
    "\n",
    "def get_tickers_from_csv(csv_path: str) -> list:\n",
    "    \"\"\"Load a comprehensive list of tickers from an external CSV file.\"\"\"\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(csv_path)    # Accept common column names for tickers\n",
    "    for col in ['symbol', 'ticker', 'Ticker', 'SYMBOL', 'Symbol']:\n",
    "        if col in df.columns:\n",
    "            tickers = df[col].dropna().unique().tolist()\n",
    "            return tickers\n",
    "    raise ValueError(f\"No ticker column found in {csv_path}. Columns found: {df.columns.tolist()}\")\n",
    "\n",
    "# Example usage:\n",
    "# Download a full US stock list from NASDAQ, NYSE, AMEX, or use a third-party source like 'eodhistoricaldata.com', 'nasdaqtrader.com', or 'stockanalysis.com'.\n",
    "# Place the CSV in your data directory, e.g., 'data/all_us_tickers.csv'.\n",
    "# all_tickers = get_tickers_from_csv('data/all_us_tickers.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7440c",
   "metadata": {},
   "source": [
    "## 2. Break Out Model Components\n",
    "Separate the workflow into modular functions for data loading, preprocessing, model definition, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d65af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading function\n",
    "def load_stock_data(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load historical stock data from CSV or other sources.\"\"\"\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Feature engineering and breakout labeling. Handles division by zero and missing data.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Example: Calculate 30-day forward return, avoid division by zero\n",
    "    df['forward_return_30d'] = np.where(\n",
    "        df['close'] != 0,\n",
    "        df['close'].shift(-30) / df['close'] - 1,\n",
    "        np.nan\n",
    "    )\n",
    "    # Label breakout: 1 if return > 0.6 (60%), else 0\n",
    "    df['breakout'] = (df['forward_return_30d'] > 0.6).astype(int)\n",
    "    return df\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    from sklearn.metrics import roc_auc_score, classification_report\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"ROC AUC: {auc:.3f}\")\n",
    "    print(classification_report(y_test, y_pred > 0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4bdf9",
   "metadata": {},
   "source": [
    "## 3. Add Data Point Functionality\n",
    "Implement a function to add or update individual data points for training or testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add or update a data point\n",
    "def add_data_point(df: pd.DataFrame, new_row: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Add or update a single data point in the DataFrame.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Assume 'date' and 'symbol' uniquely identify a row\n",
    "    mask = (df['date'] == new_row['date']) & (df['symbol'] == new_row['symbol'])\n",
    "    if mask.any():\n",
    "        df.loc[mask, :] = pd.DataFrame([new_row])\n",
    "    else:\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e76693c",
   "metadata": {},
   "source": [
    "## 4. Display and Edit Training Cell\n",
    "This cell trains the breakout classifier. You can edit model parameters or code as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675009f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training cell: Download, preprocess, and train on price data from your ticker CSV using EODHD\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Load tickers from your CSV\n",
    "csv_path = Path('data/stocks-list.csv')\n",
    "all_tickers = get_tickers_from_csv(str(csv_path))\n",
    "print(f\"Loaded {len(all_tickers)} tickers from {csv_path}\")\n",
    "\n",
    "# 2. Download historical price data for these tickers (batch or subset for demo)\n",
    "bulk_df = download_eodhd_bulk(all_tickers[:1000])  # Adjust slice as needed\n",
    "\n",
    "# 3. Ensure columns are lowercase for consistency\n",
    "bulk_df.columns = [col.lower() for col in bulk_df.columns]\n",
    "\n",
    "# 4. Check for 'close' column before proceeding\n",
    "if 'close' not in bulk_df.columns:\n",
    "    raise ValueError(f\"'close' column not found in downloaded data. Columns available: {bulk_df.columns.tolist()}\")\n",
    "\n",
    "# 5. Preprocess and label breakouts\n",
    "bulk_df = preprocess_data(bulk_df)\n",
    "\n",
    "# 6. Select features and target\n",
    "features = ['open', 'high', 'low', 'close', 'volume']  # Add more features as needed\n",
    "X = bulk_df[features]\n",
    "y = bulk_df['breakout']\n",
    "\n",
    "# 7. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 8. Train model\n",
    "clf = BreakoutStockClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 9. Evaluate\n",
    "evaluate_model(clf.model, X_test, y_test)\n",
    "\n",
    "# 10. Save model\n",
    "clf.save('breakout_classifier_xgb_stockslist.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0428fd",
   "metadata": {},
   "source": [
    "# --- Data download using your own ticker CSV (no Yahoo ticker scraping needed) ---\n",
    "import yfinance as yf\n",
    "\n",
    "# Function to download historical data for a list of tickers\n",
    "# (tickers should come from your CSV, not Yahoo API)\n",
    "def download_bulk_stock_data(tickers, start=\"2015-01-01\", end=None):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start, end=end, progress=False)\n",
    "            if not df.empty:\n",
    "                df['symbol'] = ticker\n",
    "                data[ticker] = df.reset_index()\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {ticker}: {e}\")\n",
    "    if data:\n",
    "        all_df = pd.concat(data.values(), ignore_index=True)\n",
    "        return all_df\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load and process multiple stock files efficiently\n",
    "import glob\n",
    "\n",
    "all_files = glob.glob('data/stocks/*.csv')  # Folder with many stock CSVs\n",
    "all_dfs = []\n",
    "for file in all_files:\n",
    "    df = load_stock_data(file)\n",
    "    df = preprocess_data(df)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "big_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Continue as before with big_df\n",
    "X = big_df[features]\n",
    "y = big_df['breakout']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = BreakoutStockClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "evaluate_model(clf.model, X_test, y_test)\n",
    "clf.save('breakout_classifier_xgb_large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Refined: Download and process thousands of tickers from Yahoo Finance ---\n",
    "# 1. Get a large universe of tickers\n",
    "all_tickers = get_all_us_tickers()\n",
    "print(f\"Total tickers: {len(all_tickers)}\")\n",
    "\n",
    "# 2. Download historical data for all tickers (can take a long time, consider batching)\n",
    "bulk_df = download_bulk_stock_data(all_tickers[:1000], start=\"2018-01-01\")  # Use a subset for demo\n",
    "\n",
    "# 3. Preprocess and label breakouts\n",
    "bulk_df = preprocess_data(bulk_df)\n",
    "\n",
    "# 4. Continue as before\n",
    "features = ['open', 'high', 'low', 'close', 'volume']\n",
    "X = bulk_df[features]\n",
    "y = bulk_df['breakout']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = BreakoutStockClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "evaluate_model(clf.model, X_test, y_test)\n",
    "clf.save('breakout_classifier_xgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load tickers from data/stocks-list.csv and use for training ---\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to your downloaded ticker CSV\n",
    "csv_path = Path('data/stocks-list.csv')\n",
    "\n",
    "# Load tickers\n",
    "all_tickers = get_tickers_from_csv(str(csv_path))\n",
    "print(f\"Loaded {len(all_tickers)} tickers from {csv_path}\")\n",
    "\n",
    "# Download historical data for these tickers (batch or subset for demo)\n",
    "bulk_df = download_bulk_stock_data(all_tickers[:1000], start=\"2018-01-01\")  # Adjust slice as needed\n",
    "\n",
    "# Preprocess and label breakouts\n",
    "bulk_df = preprocess_data(bulk_df)\n",
    "\n",
    "# Select features and target\n",
    "features = ['open', 'high', 'low', 'close', 'volume']\n",
    "X = bulk_df[features]\n",
    "y = bulk_df['breakout']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "clf = BreakoutStockClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(clf.model, X_test, y_test)\n",
    "\n",
    "# Save model\n",
    "clf.save('breakout_classifier_xgb_stockslist.pkl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
